# KYC-AML Task Definitions
# These configurations define tasks, their descriptions, expected outputs, and agent assignments
# Parameters can be injected using {parameter_name} syntax

# ==================== INTAKE TASKS ====================

validate_documents_task:
  description: >
    Validate and store documents with globally unique IDs.
    
    Use batch_validate_documents_tool with file paths: {file_paths}
    
    Steps:
    1. Call batch_validate_documents_tool - it handles validation, ID generation, and storage
    2. Return the result immediately - DO NOT convert PDFs to images yet
    3. PDF conversion will happen in classification stage if needed
    
    IMPORTANT: Just validate and store files. Return metadata only.
  
  expected_output: >
    JSON with:
    - validated_documents: [{document_id, original_filename, stored_path, file_size, 
      mime_type, validation_status}]
    - failed_documents: [{file_path, issues}]
    - summary: {total, valid, invalid}
  
  agent: document_intake_agent

# ==================== CLASSIFICATION TASKS ====================

classify_documents_task:
  description: >
    Classify documents using API discovery and generic REST API tools.
    
    Categories: identity_proof, address_proof, financial_statement, other
    
    Process:
    1. FOR EACH DOCUMENT - Check if PDF conversion is needed:
       a. Call check_pdf_conversion_needed_tool(document_id) to check if it's a PDF
       b. ONLY IF needs_conversion=true: Call convert_pdf_to_images_tool(document_id)
       c. IMPORTANT: Do NOT convert image files (jpg, png, etc.) - they are already images!
       d. If PDF was converted, classify the child image documents, not the PDF
    2. FOR EACH DOCUMENT TO CLASSIFY (original images or converted PDF images):
       a. Call get_classifier_api_info_tool() to discover available API endpoints
       b. Call extract_document_file_path_tool(document) to get the file path
       c. Call make_classifier_api_request(endpoint_path="/", method="POST", file_path=...) to classify
       d. Parse the API response to get predicted_class and confidence
    3. Update metadata for EACH document using update_document_metadata_tool:
       update_document_metadata_tool(
         document_id="DOC_...",
         stage_name="classification",
         status="success" or "fail",
         msg="Document classified as Passport" or error description,
         additional_data={
           "document_type": "Passport",
           "confidence": 0.95,
           "categories": ["identity_proof"],
           "requires_review": false,
           "api_response": <full raw API response dict>
         }
       )
    
    Documents: {documents}
  
  expected_output: >
    JSON with classifications array containing document_id, predicted_class, 
    confidence_score, requires_review for each document, plus a summary with 
    total count of classified documents.
  
  agent: document_classifier_agent

# ==================== EXTRACTION TASKS ====================

extract_document_data_task:
  description: >
    Extract structured data from classified documents using Google Vision API.
    
    Process (same pattern as classification):
    1. Get documents in 'classification' stage using get_documents_by_stage("classification")
    2. FOR EACH document:
       a. Call extract_text_from_image_tool(file_path=stored_path) to get Vision API response
       b. Vision API returns structured JSON: {success, text, confidence, word_count, char_count}
       c. Parse the extracted text based on document_type from classification to identify fields:
          
          For Passport/Voter ID/Driving License (identity documents):
          - Full name, Date of birth, Document number
          - Issue date, Expiry date, Issuing authority
          
          For Address proof (utility bills, bank statements):
          - Full name, Complete address
          - Document date, Issuing organization
          
          For PAN/Aadhar:
          - Name, ID number, Date of birth
       
       d. Update metadata using update_document_metadata_tool:
          update_document_metadata_tool(
            document_id="DOC_...",
            stage_name="extraction",
            status="success" or "fail",
            msg="Successfully extracted structured fields from document" or error description,
            additional_data={
              "extracted_fields": {
                "name": "John Doe",
                "document_number": "A12345678",
                "dob": "1990-01-01",
                ...
              },
              "raw_text": full_extracted_text,
              "confidence": vision_api_confidence,
              "word_count": word_count,
              "extraction_quality": calculated_quality_score,
              "fields_found": ["name", "document_number", "dob"],
              "fields_missing": ["expiry_date"],
              "vision_api_response": <full Vision API response>
            }
          )
    
    IMPORTANT:
    - Vision API provides raw text and confidence
    - Your job is to parse the text and extract structured fields based on document_type
    - Use document_type from classification to know what fields to look for
    - Mark extraction quality based on how many expected fields were found
  
  expected_output: >
    JSON object with:
    {
      "extractions": [
        {
          "document_id": "DOC_xxx",
          "document_type": "Passport",
          "success": true,
          "extracted_fields": {
            "name": "John Doe",
            "document_number": "A12345678",
            "dob": "1990-01-01",
            "issue_date": "2020-01-01",
            "expiry_date": "2030-01-01"
          },
          "raw_text": "full text from vision api",
          "confidence": 0.95,
          "extraction_quality": 0.90,
          "fields_found": 5,
          "fields_missing": 0
        }
      ],
      "summary": {
        "total": 5,
        "successful": 4,
        "failed": 1,
        "average_quality": 0.88
      }
    }
  
  agent: document_extraction_agent

batch_extract_documents_task:
  description: >
    Extract data from multiple documents in batch for case {case_id}.
    
    Batch processing strategy:
    1. Group documents by type for consistent extraction
    2. Use appropriate OCR API for each document type
    3. Implement parallel processing where possible
    4. Aggregate results with quality metrics
    5. Generate extraction summary report
    
    Documents to process: {documents}
    Priority: {priority}
  
  expected_output: >
    JSON object containing:
    - extractions: List of individual extraction results (same format as extract_document_data_task)
    - summary:
      - total_documents: Count of documents processed
      - successful_extractions: Count of successful extractions
      - failed_extractions: Count of failed extractions
      - average_quality_score: Mean extraction quality across all documents
      - total_processing_time: Time taken for batch
      - case_id: Case identifier
  
  agent: document_extraction_agent

# ==================== WORKFLOW COORDINATION TASKS ====================

orchestrate_workflow_task:
  description: >
    Orchestrate the complete document processing workflow for case {case_id}.
    
    Workflow stages:
    1. Document intake and validation
    2. Document classification
    3. Data extraction
    4. Quality validation and review
    5. Result aggregation and reporting
    
    Coordination responsibilities:
    - Monitor progress of each stage
    - Handle errors and retries
    - Maintain workflow state
    - Coordinate between specialized agents
    - Make decisions about workflow progression
    - Escalate issues requiring human intervention
    
    Input documents: {file_paths}
  
  expected_output: >
    JSON object containing:
    - case_id: Case identifier
    - workflow_status: "completed", "partial", or "failed"
    - stages_completed: List of completed workflow stages
    - intake_results: Results from intake stage
    - classification_results: Results from classification stage
    - extraction_results: Results from extraction stage
    - quality_metrics:
      - overall_quality_score: 0.0-1.0
      - documents_requiring_review: Count
      - processing_time: Total time in seconds
    - errors: List of any errors encountered
    - recommendations: Suggested next steps or actions
  
  agent: supervisor_agent

validate_and_report_task:
  description: >
    Validate all processing results for case {case_id} and generate comprehensive report.
    
    Validation checks:
    1. Verify all documents were processed
    2. Check data completeness for each document
    3. Validate field consistency across documents
    4. Identify any data quality issues
    5. Check compliance with KYC/AML requirements
    
    Report generation:
    1. Create summary of all processed documents
    2. Highlight documents requiring review
    3. List extracted key information
    4. Include quality metrics
    5. Provide recommendations for case progression
  
  expected_output: >
    Comprehensive JSON report with:
    - case_summary: Overview of case processing
    - document_inventory: List of all documents with status
    - extracted_information: Consolidated data from all documents
    - quality_assessment: Quality metrics and scores
    - compliance_checklist: KYC/AML requirement coverage
    - review_required: List of items needing human review
    - recommendations: Next steps for case handling
    - report_timestamp: ISO 8601 timestamp
  
  agent: supervisor_agent
